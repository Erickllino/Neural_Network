{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"cifar10\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Organizando os Dadoas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_png  = dataset['train']['img']\n",
    "y_train      = dataset['train']['label']\n",
    "\n",
    "X_test_png  = dataset['test']['img']\n",
    "y_test      = dataset['test']['label']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "X_test  = []\n",
    "transf = transforms.ToTensor()\n",
    "\n",
    "\n",
    "for x in X_train_png:\n",
    "    prov = transf(x)\n",
    "    X_train.append(prov)\n",
    "    \n",
    "X_train = X_train[0]\n",
    "\n",
    "    \n",
    "for x in X_test_png:\n",
    "    prov = transf(x)\n",
    "    X_test.append(prov)\n",
    "\n",
    "X_test = X_test[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.6980, 0.6980, 0.6980,  ..., 0.6667, 0.6588, 0.6471],\n",
       "         [0.7059, 0.7020, 0.7059,  ..., 0.6784, 0.6706, 0.6588],\n",
       "         [0.6941, 0.6941, 0.6980,  ..., 0.6706, 0.6627, 0.6549],\n",
       "         ...,\n",
       "         [0.4392, 0.4431, 0.4471,  ..., 0.3922, 0.3843, 0.3961],\n",
       "         [0.4392, 0.4392, 0.4431,  ..., 0.4000, 0.4000, 0.4000],\n",
       "         [0.4039, 0.3922, 0.4039,  ..., 0.3608, 0.3647, 0.3569]],\n",
       "\n",
       "        [[0.6902, 0.6902, 0.6902,  ..., 0.6588, 0.6510, 0.6392],\n",
       "         [0.6980, 0.6941, 0.6980,  ..., 0.6706, 0.6627, 0.6510],\n",
       "         [0.6863, 0.6863, 0.6902,  ..., 0.6627, 0.6549, 0.6471],\n",
       "         ...,\n",
       "         [0.4196, 0.4275, 0.4314,  ..., 0.3804, 0.3686, 0.3725],\n",
       "         [0.4000, 0.4039, 0.4039,  ..., 0.3725, 0.3647, 0.3608],\n",
       "         [0.3765, 0.3647, 0.3725,  ..., 0.3294, 0.3373, 0.3294]],\n",
       "\n",
       "        [[0.7412, 0.7412, 0.7412,  ..., 0.7059, 0.6941, 0.6824],\n",
       "         [0.7490, 0.7451, 0.7490,  ..., 0.7137, 0.7059, 0.6941],\n",
       "         [0.7373, 0.7373, 0.7412,  ..., 0.7059, 0.6980, 0.6902],\n",
       "         ...,\n",
       "         [0.4196, 0.4235, 0.4314,  ..., 0.3686, 0.3647, 0.3725],\n",
       "         [0.3961, 0.4000, 0.4039,  ..., 0.3647, 0.3569, 0.3569],\n",
       "         [0.3608, 0.3529, 0.3686,  ..., 0.3137, 0.3137, 0.3020]]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CIFAR10(Dataset):\n",
    "    \n",
    "    def __init__(self,X,y):\n",
    "        \n",
    "        \n",
    "        self.X = X\n",
    "        self.y = y\n",
    "          \n",
    "    def __getitem__(self,idx):\n",
    "        return self.X[idx],self.y[idx]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    \n",
    "    \n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(CIFAR10(X_train,y_train),  batch_size = len(X_train) )\n",
    "#test_dl  = DataLoader(CIFAR10(X_test_T, y_test_T),  batch_size = len(X_test_T) )\n",
    "                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Criando o Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP_Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.L1  = nn.Linear(32*32,64)\n",
    "        self.L2  = nn.Linear(64, 32)\n",
    "        self.L3  = nn.Linear(32,10)\n",
    "        self.A   = nn.ReLU()\n",
    "        \n",
    "        \n",
    "    def forward(self):\n",
    "        \n",
    "        x = self.L1(x) \n",
    "        x = self.A(x)\n",
    "        x = self.L2(x) \n",
    "        x = self.A(x)\n",
    "        x = self.L2(x)\n",
    "        x = self.A(x)\n",
    "        \n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def training( N_Epochs, model, loss_fn, opt  ):\n",
    "    \n",
    "    loss_list = []\n",
    "    \n",
    "    for epoch in tqdm(range(N_Epochs+1)):\n",
    "        for xb, yb in train_dl:\n",
    "            \n",
    "            \n",
    "            \n",
    "            y_pred = model(xb.float())\n",
    "            loss   = loss_fn(y_pred, yb.long())\n",
    "        \n",
    "            \n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "        \n",
    "            loss_list.append(loss.item())\n",
    "    \n",
    "    L1_weights = MLP_Model().L1.weight.detach()\n",
    "    L2_weights = MLP_Model().L2.weight.detach()\n",
    "    L3_weights = MLP_Model().L3.weight.detach()\n",
    "    L4_weights = MLP_Model().L4.weight.detach()\n",
    "    \n",
    "       \n",
    "    \n",
    "    plt.figure(figsize = (14,6))\n",
    "    plt.title(\"cost decay\")\n",
    "    plt.plot(loss_list)\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.ylabel(\"cost\")\n",
    "    \n",
    "    return L1_weights, L2_weights, L3_weights, L4_weights"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
